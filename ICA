import numpy as np

class ICA:
    def __init__(self, m):
        self.W = np.random.rand(m, m)
    def gradientDescentICA (self, X, alpha, max_likehood ):
        i = 0
        while ((i < X.shape[0]) and (np.abs(self.cost_function(X)) < max_likehood)):
            dJ = self.gradient( X[i, :]);
            self.W = self.W + alpha * dJ;
            i += 1
        return  self.W
    def cost_function(self, X):
        return np.sum(np.sum(np.log(g_derivative(self.W.T.dot(X.T))), axis = 0) + np.log(np.abs(np.linalg.det(self.W))))
    def gradient(self, x):
        x1 = (np.ones((x.shape[0], 1)).T - 2 * g(self.W.T.dot(x))).T
        x2 = np.zeros((x1.shape[0], x1.shape[0]))
        for i in range(x1.shape[0]):
            for j in range(x1.shape[0]):
                x2[i, j] = x1[i] * x[j]
        return x2 + np.linalg.inv(self.W.T)
    def calculate(self, x):
        return self.W.dot(x)
def g(z):
    return 1 / (1 + np.exp(-z) )  # model function
def g_derivative(z):
    return g(z) * (1 - g(z))


